# APPO

在文章 [13]中，作者提出了另外一种多GPU之间异步更新的方法，并且在PPO算法上进行了测试，称之为APPO。跟DD-PPO不同，APPO的多GPU架构更类似于Parameter-Server架构，但是更新方式又有明显不同。其梯度更新方法主要有以下三步组成

1. 本地Worker计算梯度，并存在GPU上
1. 从Master上拉取最新的模型
1. 在最新的模型上应用步骤1的梯度，并将新模型写入到Master上

为了解决第2步和第3步异步重复读写的问题，Worker在进行这两步时引入了一个全局锁。不过这产生了一个新问题，当Worker变多时，大量的Worker都在竞争这个全局锁，降低框架的整体效率。为了进一步解决这个问题，作者提出了一种解决思路，将模型分成几个部分（chunk），每次只拉取和更新一个部分，每个部分各自拥有一个全局锁，这样不同的Worker就可以在同一时刻更新模型的不同部分了。
相比于A3C架构，APPO的Master不再成为计算的瓶颈。Master只负责存储最新模型，所有的梯度计算和模型更新都放在了Worker上，天然起到了一个负载均衡的效果。但是由于需要将模型分成多个部分，这本身带来了一定的开发负担，不同的网络结构如何分块本身就比较复杂，导致通用性不是很高。[1]


[1]: https://zhuanlan.zhihu.com/p/328284456
