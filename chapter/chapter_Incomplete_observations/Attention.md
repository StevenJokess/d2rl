# 结合Attention机制

随着视觉注意力机制在目标跟踪和机器翻译等领域的成功, Sorokin等受此启发提出深度注意力递归Q网络 (deep attentionecurrent Q network, DARQN). 它能够选择性地重点关注相关信息区域, 减少深度神经网络的参数数量和计算开销[1]


[1]: http://pg.jrj.com.cn/acc/Res/CN_RES/INDUS/2023/2/9/27c20431-8ed3-4562-83b5-5c82706f28a5.pdf
