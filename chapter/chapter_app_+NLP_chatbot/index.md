

<!--
 * @version:
 * @Author:  StevenJokess（蔡舒起） https://github.com/StevenJokess
 * @Date: 2023-10-25 23:19:44
 * @LastEditors:  StevenJokess（蔡舒起） https://github.com/StevenJokess
 * @LastEditTime: 2023-11-06 10:04:12
 * @Description:
 * @Help me: make friends by a867907127@gmail.com and help me get some “foreign” things or service I need in life; 如有帮助，请资助，失业3年了。![支付宝收款码](https://github.com/StevenJokess/d2rl/blob/master/img/%E6%94%B6.jpg)
 * @TODO::
 * @Reference:
-->
# 应用：聊天机器人（ChatBot）

本章介绍强化学习的应用之一——聊天机器人，包括：

![基于神经网络的语言模型演进历程](../../../img/NN_based_language_model_developing.png)

- NLP：自然语言处理的历史发展
- NLP_app：自然语言处理的应用
- LM(RNN_LSTM_GRU)：语言模型、RNN、LSTM、GRU
- Attention_Mechanism：注意力机制。自注意力机制，是之后Transformer 模型强大的秘诀
- Encoder-Decoder&Seq2Seq：Encoder-Decoder 模型
- Pretrain1(NNLM_Word2Vec_Glove)：预训练
- Pretrain2_LLM(Transformer)：大语言模型、经典大语言模型 Transformer（其后续影响了ELMo、GPT、BERT）
- ELMo：
- GPT1：早期GPT的发展历程，以及预训练过程（Pretrain）
- BERT：
- GPT2：思维链（COT）、提示词（Prompt）
- Prompt_Learning(Prompt_Tuning)：预训练语言模型加持下的Prompt Learning成为了NLP的第四范式
- GPT3：GPT3
- RL_in_NLP：回顾强化学习在自然语言处理中的应用
- GPT3.5(+RLHF=InstructGPT)：从人类反馈强化学习（RLHF），并将其应用到GPT。
- Codex&Github_CoPilot：
- ChatGPT：
- GPT4：之后GPT的发展历程，应用于聊天。
- ChatGPT_Plugins：介绍 ChatGPT Plugins原理
- moreGPT：介绍AutoGPT、MetaGPT、ChatGPT for Robotics
- Open_source_LLM：介绍LLaMA、Alpaca
- other_LLM：介绍Claude
- Chinese_LLM：介绍中国的大语言模型，开源ChatRWKV、



```toc
:maxdepth: 2

NLP
NLG(by_NN_for_Dia)
LM(RNN_LSTM_GRU)
LLM(Transformer)
Bert_VS_GPT
LLM(Transformer)

ChatGPT(RLHF)
ChatGPT_Plugins
AutoGPT
MetaGPT
```
