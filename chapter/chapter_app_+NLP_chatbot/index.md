

<!--
 * @version:
 * @Author:  StevenJokess（蔡舒起） https://github.com/StevenJokess
 * @Date: 2023-10-25 23:19:44
 * @LastEditors:  StevenJokess（蔡舒起） https://github.com/StevenJokess
 * @LastEditTime: 2024-05-15 23:07:04
 * @Description:
 * @Help me: make friends by a867907127@gmail.com and help me get some “foreign” things or service I need in life; 如有帮助，请资助，失业3年了。![支付宝收款码](https://github.com/StevenJokess/d2rl/blob/master/img/%E6%94%B6.jpg)
 * @TODO::
 * @Reference:
-->
# 应用：聊天机器人（ChatBot）

本章介绍强化学习的应用之一——聊天机器人，包括：

![基于神经网络的语言模型演进历程](../../../img/NN_based_language_model_developing.png)

- NLP：自然语言处理的历史发展
- LM(RNN_LSTM_GRU)：语言模型、RNN、LSTM、GRU
- Attention_Mechanism：注意力机制。自注意力机制，是之后Transformer 模型强大的秘诀
- Encoder-Decoder&Seq2Seq：Encoder-Decoder 模型
- Pretrain_LM(NNLM_Word2Vec_Glove)：预训练
- Pretrain_LLM(Transformer)：大语言模型、经典大语言模型 Transformer（其后续影响了ELMo、GPT、BERT）
- ELMo：
- GPT1：早期GPT的发展历程，以及预训练过程（Pretrain）
- BERT：
- GPT2：思维链（COT）、提示词（Prompt）
- Prompt_Learning(Prompt_Tuning)：预训练语言模型加持下的Prompt Learning成为了NLP的第四范式
- GPT3：GPT3
- RL_in_NLP：回顾强化学习在自然语言处理中的应用
- GPT3.5(+RLHF=InstructGPT)：从人类反馈强化学习（RLHF），并将其应用到GPT。
- Codex&Github_CoPilot：GPT应用于代码生成。
- ChatGPT&Newbing：GPT应用于聊天机器人、搜索。
- GPT4：介绍 ChatGPT Plugins、GPT4V、GPTstore、GPT4-Turbo
- more_about_ChatGPT：介绍AutoGPT、MetaGPT、ChatGPT for Robotics
- Safety_AGI:
- other_LLM：介绍外国的大语言模型，开源有LLaMA、Alpaca；不开源的有Claude、Gemini等；介绍中国的大语言模型，开源ChatRWKV等；不开源的
- ChatGPT_PUA_Ilya：

？ NLG(by_NN_for_Dia)

```toc
:maxdepth: 2

NLP

LM(RNN_LSTM_GRU)
LLM(Transformer)
Bert_VS_GPT
LLM(Transformer)



```

TOOD: https://blog.csdn.net/qq_56591814/article/details/130542583
