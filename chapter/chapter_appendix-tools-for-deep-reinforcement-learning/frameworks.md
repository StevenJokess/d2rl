

<!--
 * @version:
 * @Author:  StevenJokess（蔡舒起） https://github.com/StevenJokess
 * @Date: 2023-04-28 23:18:27
 * @LastEditors:  StevenJokess（蔡舒起） https://github.com/StevenJokess
 * @LastEditTime: 2023-04-28 23:26:35
 * @Description:
 * @Help me: make friends by a867907127@gmail.com and help me get some “foreign” things or service I need in life; 如有帮助，请赞助，失业3年了。![支付宝收款码](https://github.com/StevenJokess/d2rl/blob/master/img/%E6%94%B6.jpg)
 * @TODO::
 * @Reference:
-->
#

博弈训练测试框架及平台
4. 1 MALib
MALib
[57]是首个专门面向基于种群的多智能体
强化学习的开源大规模并行训练框架( 官网链接:
https: / / malib. io / )。 支 持 自 我 博 弈、 联 盟 训 练 及
PSRO 等多种博弈训练方式,已对接多种多智能体
环境。
4. 2 POAC
部分可观测异步智能体协同( POAC) 平台[58] 是
多智能体强化学习算法的标准测试环境(官网链接:
http: / / turingai. ia. ac. cn / app / detail / 30),可用于兵棋
AI 人机对抗挑战,支持自我博弈、人机对抗等模式。
4. 3 Go-Bigger
Go-Bigger 是 OpenDILab 推出的多智能体强化学
习 博 弈 训 练 环 境 ( 文 档 链 接: https: / / gobigger.
readthedocs. io / en / latest / index. html),涵盖自我博弈、
联盟训练等多种博弈训练方式,提供了直观、高效的
平台。
4. 4 RoboSumo
RoboSumo
[39]是多智能体竞争环境,具有模拟物
理特征,使用相扑规则,智能体观察敌我位置、速度等
参数,在连续动作空间进行自我博弈训练。MAlib


基于种群的多智能体强化学习：算法与系统[1]

[1]: https://www.bilibili.com/video/BV1FL4y1z7eL/?vd_source=bca0a3605754a98491958094024e5fe3
