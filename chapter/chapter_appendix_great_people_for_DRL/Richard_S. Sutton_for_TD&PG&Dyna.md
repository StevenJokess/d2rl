# Richard S. Sutton

Richard S. Sutton是加拿大的一个计算机科学家，当前任职于iCORE大学计算机科学系。Sutton是强化学习领域巨擘，在temporal difference learning, policy gradient methods, the Dyna architecture等方面都有重大贡献。自2003年起，Sutton就出任iCORE大学计算机科学系的教授，在这里他领导了强化学习和人工智能实验室(RLAI)。

https://www.ualberta.ca/science/about-us/contact-us/faculty-directory/rich-sutton

## 与Andrew Barto合著ReinforcementLearningAn Introduction

Andrew Barto 是Massachusetts大学Amherst分校的教授, 已于2012年退休.退休前, 他是Massachusetts大学Amherst分校自治学习实验室主任.目前, 他是assachusetts大学神经科学和行为项目的准会员, Neural Computation 副主编, Machine Learning Research杂志顾问,  Adaptive Behavior的编辑[1]

## 苦涩的教训

70 年的人工智能研究史告诉我们，利用计算能力的一般方法最终是最有效的方法。这个归摩尔定律解释，或者它对每单位计算成本持续指数级下降的概括。大部分 AI 研究都是在认为智能体可用的计算为恒定的情况下进行的（在这种情况下，利用人类知识是提高性能的唯一方法），但是，在比典型研究项目稍长的时间尺度内，我们不可避免地会需要大量的计算。

要在短期内有所提升，研究人员要利用专门领域的人类知识。但如果想要长期的获得提升，利用计算能力才是王道。这两者本无需对立，但实际上它们往往如此。花时间研究一个，就会忽略另一个。利用人类知识的方法容易复杂化，导致其不太适合利用计算的方法。很多例子表明 AI 研究人员对这些教训的认识太晚，因此我们有必要回顾一些突出的例子。

在计算机国际象棋中，1997 年击败世界冠军卡斯帕罗夫的方法基于大量深度搜索。当时，大多数 AI 计算机象棋研究人员沮丧地发现了这一点，他们的方法是利用人类对象棋特殊结构的理解。当这个利用硬件和软件的基于搜索的更简单方法被证明更有效时，这些基于人类知识的象棋研究人员却仍不肯认输。他们认为虽然这个「暴力」搜索方法此次赢了，但它并不是一个普遍的策略，无论如何它不是人类下国际象棋的方法。这些研究人员希望基于人类输入的方法获胜，但结果却令他们失望了。

计算机围棋中也有类似的研究进展模式，只是晚了 20 年。最初研究人员努力利用人类知识或游戏的特殊性来避免搜索，但所有的努力都被证明没什么用，因为搜索被大规模地有效应用。同样重要的是利用自我对弈（self play）来学习一种价值函数（就像在很多其他游戏甚至国际象棋中一样，虽然在 1997 年首次击败世界冠军的比赛中没起到什么作用）。通过自我对弈学习和一般学习有点像搜索，因为它能让大量的计算发挥作用。搜索和学习是人工智能研究中利用大量计算的两种最重要技术。在计算机围棋中，就像计算机国际象棋中一样，研究人员最初是想通过人类理解（这样无需太多搜索）来实现目的，只是在后来，通过搜索和学习才取得了巨大成功。

在语音识别领域，早在上世纪 70 年代就有一个由 DARPA 赞助的竞赛。参赛者利用了很多利用人类知识的特殊方法：单词、因素和人类声道等。另一方面，还有人利用了基于隐马尔可夫模型的新方法，这些方法在本质上更具统计性，计算量也更大。同样，统计方法战胜了基于人类知识的方法。这导致了自然语言处理领域的重大改变，过去几十年来，统计和计算在该领域逐渐占据主导地位。深度学习最近在语音识别中的兴起正是朝着这一方向迈出的最新一步。

深度学习方法更少依赖人类知识，使用更多的计算，并且伴有大量训练集的学习，从而生成更好的语音识别系统。就像在游戏中一样，研究人员总是试图令系统按照他们的思维方式进行运作——他们试图将知识放在系统中——但事实证明，最终结果往往事与愿违，并且极大浪费了研究人员的时间。但是通过摩尔定律，研究人员可以进行大量计算，并且找到一种有效利用的方法。

计算机视觉领域存在相似的模式。早期方法认为视觉是为了搜索边缘、广义圆柱体或者取决于 SIFT 特征。但是今天，所有这些方法都被抛弃了。现代深度学习神经网络仅使用卷积和某些不变性的概念即可以取得更好的效果。

这是一个非常大的教训。因为我们还在犯同一类错误，所以依然未能彻底了解人工智能领域。要看到这一点并且有效地避免重蹈覆辙，我们必须理解这些错误为何会让我们误入歧途。我们必须吸取惨痛的教训，即从长远看，固守我们的思维模式是行不通的。痛苦的教训基于以下历史观察结果：

AI 研究人员常常试图在自身智能体中构建知识，

从短期看，这通常是有帮助的，能够令研究人员满意，

但从长远看，这会令研究人员停滞不前，甚至抑制进一步发展，

突破性进展最终可能会通过一种相反的方法——基于以大规模计算为基础的搜索和学习。最后的成功往往带有一丝苦涩，并且无法完全消化，因为这种成功不是通过一种令人喜欢、以人为中心的方法获得的。

我们应该从痛苦的教训中学到的一点：通用方法非常强大，这类方法会随着算力的增加而继续扩展，即使可用计算变得非常大。搜索和学习似乎正是两种以这种方式随意扩展的方法。

我们从痛苦的教训中学到的第二个普遍观点是，意识的实际内容是极其复杂的；我们不应该试图通过简单方法来思考意识的内容，如思考空间、物体、多智能体或者对称性。所有这些都是任意的、本质上复杂的外部世界的一部分。它们不应该被固有化，其原因是复杂性是无穷无尽的；相反，我们只应该构建可以找到并捕获这种任意复杂性的元方法。这些方法的关键在于它们能够找到很好的近似值，但对它们的搜索应由我们的方法完成，而不是我们自己。我们希望 AI 智能体可以像我们一样发现新事物，而不是重新找到我们所发现的。在我们发现的基础上构建只能令人更加难以看清发现过程的完成情况。[2]



原文链接：[3]


[1]: https://cloud.tencent.com/developer/article/1616659
[2]: https://www.linkresearcher.com/information/01af2812-2cbc-4c3b-bec8-2e3701c6ac2f
[3]: http://www.incompleteideas.net/IncIdeas/BitterLesson.html
