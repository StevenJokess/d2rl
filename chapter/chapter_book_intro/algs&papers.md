

<!--
 * @version:
 * @Author:  StevenJokess（蔡舒起） https://github.com/StevenJokess
 * @Date: 2023-06-04 20:48:28
 * @LastEditors:  StevenJokess（蔡舒起） https://github.com/StevenJokess
 * @LastEditTime: 2023-08-31 21:51:54
 * @Description:
 * @Help me: make friends by a867907127@gmail.com and help me get some “foreign” things or service I need in life; 如有帮助，请赞助，失业3年了。![支付宝收款码](https://github.com/StevenJokess/d2rl/blob/master/img/%E6%94%B6.jpg)
 * @TODO::
 * @Reference:
-->
# 涉及的算法以及对应的论文总结

- Sarsa:
  - ![On-Line Q-Learning Using Connectionist Systems](../../papers_PDF/rummery_tr166.pdf) http://mi.eng.cam.ac.uk/reports/svr-ftp/auto-pdf/rummery_tr166.pdf
  - 【SARSA was not actually called SARSA by Rummery and Niranjan in their 1994 paper “On-Line Q-Learning Using Connectionist Systems” . The authors preferred “Modified Connectionist Q-Learning.” The alternative was suggested by Richard Sutton and it appears that SARSA stuck.】
  - ![Rummery, G. A., & Niranjan, M. (1994). On-line Q-learning using connectionist systems (Vol. 37). Cambridge, England: University of Cambridge, Department of Engineering.](../../papers_PDF/sutton-96.pdf) http://incompleteideas.net/papers/sutton-96.pdf
- Double Q learning: ![Double Q learning](../../papers_PDF/NIPS-2010-double-q-learning-Paper.pdf)https://proceedings.neurips.cc/paper/3964-double-q-learning.pdf



- PPO: ![Proximal Policy Optimization Algorithms](../../papers_PDF/PPO.pdf)(https://arxiv.org/abs/1707.06347)
- AlphaGo Zero：![Mastering Chess and Shogi by Self-Play with a General Reinforcement Learning Algorithm](../../papers_PDF/) https://arxiv.org/abs/1712.01815
-

