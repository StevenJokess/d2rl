

<!--
 * @version:
 * @Author:  StevenJokess（蔡舒起） https://github.com/StevenJokess
 * @Date: 2023-11-09 08:20:06
 * @LastEditors:  StevenJokess（蔡舒起） https://github.com/StevenJokess
 * @LastEditTime: 2023-11-09 08:20:16
 * @Description:
 * @Help me: make friends by a867907127@gmail.com and help me get some “foreign” things or service I need in life; 如有帮助，请资助，失业3年了。![支付宝收款码](https://github.com/StevenJokess/d2rl/blob/master/img/%E6%94%B6.jpg)
 * @TODO::
 * @Reference:
-->
# MB-MPO

基于模型的元策略优化（MB-MPO）--2018年：使用元学习来选择集成中哪个动态模型最能优化策略并减少模型偏差。这种元优化允许MBRL在更低的样本中更接近于渐进的无模型性能。[1]

[1]: https://www.niaogebiji.com/article-70242-1.html
