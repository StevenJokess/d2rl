# 介绍

自监督强化学习(Self-Supervised Reinforcement Learning)：学习一个观测的低维空间表示，即输入数据的压缩映射，能够有效解决直接用高维度数据学习控制策略中产生的维度灾难问题，有四种方式：
状态表征 (State Representation)：对环境中的状态进行表征，提取状态中与学习任务相关的信息以提升例如值函数、策略函数在状态空间中学习效率，或提取与单学习任务无关而对多任务通用的信息使得在多任务的学习中迁移状态表征来泛化和加速。
动作表征 (Action Representation)：对动作进行表征，压缩大的、高维的动作空间，约减探索和学习的采样开销。提取动作语义，表征动作空间的内在结构，提升函数在动作空间中的近似与泛化表现，提升学习的效果。
策略表征 (Policy Representation)：对策略进行表征，使得值函数、策略影响的环境动态等在策略空间能够泛化，拓展强化学习算法的研究领域。压缩策略空间，提供策略表征空间策略优化的可能。提供分析策略学习、演进过程的方式。
任务/环境表征 (Task/Environment Representation)：对强化学习学习任务和环境进行表征，在表征空间建立多任务、多环境的相似与区别，使得多任务、多环境的学习互相泛化和促进。
