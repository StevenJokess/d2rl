# 多智能体深度强化学习（Multi-agent DRL）

在面对一些真实场景下的复杂决策问题时，单
agent 系统的决策能力是远远不够的。例如在拥有多
玩家的Atari  2600 游戏中，要求多个决策者之间存
在相互合作或竞争的关系。因此在特定的情形下，
需要将DRL 模型扩展为多个agent 之间相互合作、
通信及竞争的多agent 系统。

1. 突发行为分析（Analysis of emergent behaviors），主要侧重点是分析和评估单智能体中的DRL算法；
2. 智能体通信（Learning communication），智能体用通信协议共享信息，比如一些直观消息或一个共享内存；
3. 智能体合作（Learning cooperation），主要应用在合作场景或混合（既有合作也有对抗）场景；
4. 智能体建模（Agents modeling agents），不仅有助于智能体之间的合作，还有助于建模对手智能体的推断目标以及考虑其他智能体的学习行为。

## 游戏环境

游戏是探索人工智能（AI）的理想环境，在游戏中可以开发和评估解决问题的技术，并将其应用于更复杂的现实世界问题。过去十年间，人工智能被广泛应用于多种不同的游戏，取得令人瞩目的成就，如Atari，DOTA2，poker等。随着能力的不断提高，研究者一直在寻求复杂度更高的游戏，以捕捉解决科学和现实世界问题所需的不同智能元素。

###

### 星际争霸

《星际争霸》被认为是最具挑战性的实时战略(RTS)游戏之一，是当前我们的主要研究方向。游戏要求玩家与对方进行即时对抗，选择合适的策略，通过资源采集、基地建造、科技发展等形式，击败对方。为了赢得比赛，AI需要学会实现多种不同的策略，以适应具体的游戏环境，是我们研究的一大难点。

1. 博弈论：游戏不存在固定不变的策略，AI需要根据实际场景，选择合适的策略。
2. 部分观测信息：与象棋围棋等游戏不同，在星际争霸中，AI只能观测到部分环境信息，需要手动控制单位通过“侦察”来获得关键信息。
3. 实时性：AI需要在游戏中根据实际环境，做出实时的操作。
4. 更大的行动空间：智能体数目增多，带来了更大的动作空间，AI要在更大的行动空间中找到合适的策略。

[1]: https://gr.xjtu.edu.cn/web/zeuslan/deep-reinforcement-learning
